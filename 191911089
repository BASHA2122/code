import cv2
import numpy as np
import os
import matplotlib.pyplot as plt
from sklearn.preprocessing import LabelEncoder

from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC

from sklearn.metrics import accuracy_score, classification_report
from sklearn.metrics import confusion_matrix
from seaborn import heatmap

import tensorflow as tf

!pip install opendatasets
import opendatasets as od
od.download('https://www.kaggle.com/datasets/msambare/fer2013')

train_data = os.listdir('/content/fer2013/train')
test_data = os.listdir('/content/fer2013/test')

train_X = []
train_y = []

for i in train_data:
    for j in os.listdir('/content/fer2013/train/'+i):
        img = cv2.imread('/content/fer2013/train/'+i+'/'+j)
        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        img = cv2.resize(img, (100,100))
        img = img.flatten()
        train_X.append(img)
        train_y.append(i)

test_X = []
test_y = []

for i in test_data:
    for j in os.listdir('/content/fer2013/test/'+i):
        img = cv2.imread('/content/fer2013/test/'+i+'/'+j)
        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        img = cv2.resize(img, (100,100))
        img = img.flatten()
        test_X.append(img)
        test_y.append(i)


le = LabelEncoder()
train_y = le.fit_transform(train_y)
test_y = le.transform(test_y)

train_X = np.array(train_X)
train_y = np.array(train_y)

test_X = np.array(test_X)
test_y = np.array(test_y)

train_X.shape, train_y.shape, test_X.shape, test_y.shape

## Dense Neural Network

model = tf.keras.models.Sequential([
    tf.keras.layers.Dense(64, activation='relu', input_shape=(10000,)),
    tf.keras.layers.Dense(32, activation='relu'),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(32, activation='relu'),
    tf.keras.layers.Dense(1, activation='sigmoid')
])

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

history = model.fit(train_X, train_y, epochs=10, validation_data=(test_X, test_y))

pred = model.predict(test_X)
pred = np.round(pred)
pred = pred.astype(int)
pred = pred.flatten()

dense_acc = accuracy_score(test_y, pred)
print('Accuracy: ', dense_acc)

dense_cm = confusion_matrix(test_y, pred)
heatmap(dense_cm, annot=True, fmt='d')

## Logistic Regression

log_reg = LogisticRegression(max_iter=1000)
log_reg.fit(train_X, train_y)

pred = log_reg.predict(test_X)
log_reg_acc = accuracy_score(test_y, pred)
print('Logistic Regression Accuracy: ', log_reg_acc)

log_cm = confusion_matrix(test_y, pred)
heatmap(log_cm, annot=True, fmt='d')

#Linear Regression

from sklearn.linear_model import LinearRegression
lin_reg = LinearRegression()
lin_reg.fit(train_X, train_y)

pred = lin_reg.predict(test_X)
lin_reg_acc = accuracy_score(test_y, pred)
print('Logistic Regression Accuracy: ', lin_reg_acc)

lin_cm = confusion_matrix(test_y, pred)
heatmap(log_cm, annot=True, fmt='d')

## Support Vector Machine

clf_svc = SVC()
clf_svc.fit(train_X, train_y)

pred = clf_svc.predict(test_X)
svc_acc = accuracy_score(test_y, pred)
print('SVC Accuracy: ', svc_acc)

svc_cm = confusion_matrix(test_y, pred)
heatmap(svc_cm, annot=True, fmt='d')

## CNN

train_X = []
train_y = []

for i in train_data:
    for j in os.listdir('/content/fer2013/train/'+i):
        img = cv2.imread('/content/fer2013/train/'+i+'/'+j)
        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        img = cv2.resize(img, (100,100))
        train_X.append(img)
        train_y.append(i)

test_X = []
test_y = []

for i in test_data:
    for j in os.listdir('/content/fer2013/test//'+i):
        img = cv2.imread('/content/fer2013/test//'+i+'/'+j)
        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        img = cv2.resize(img, (100,100))
        test_X.append(img)
        test_y.append(i)

train_y = le.fit_transform(train_y)
test_y = le.transform(test_y)

train_X = np.array(train_X)
train_y = np.array(train_y)

test_X = np.array(test_X)
test_y = np.array(test_y)

model = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(100,100,1)),
    tf.keras.layers.MaxPooling2D((2,2)),
    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D((2,2)),
    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D((2,2)),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(32, activation='relu'),
    tf.keras.layers.Dense(1, activation='sigmoid')
])

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

history = model.fit(train_X, train_y, epochs=10, validation_data=(test_X, test_y))

pred = model.predict(test_X)
pred = np.round(pred)
pred = pred.astype(int)
pred = pred.flatten()

conv_acc = accuracy_score(test_y, pred)
print('Accuracy: ', conv_acc)

conv_cm = confusion_matrix(test_y, pred)
heatmap(conv_cm, annot=True, fmt='d')

### Dense vs Logistic Regression
plt.bar(['Dense', 'Logistic Regression'], [dense_acc, log_reg_acc])

### Dense vs SVC
plt.bar(['Dense', 'SVC'], [dense_acc, svc_acc])

### Dense vs Convolutional
plt.bar(['Dense', 'Convolutional'], [dense_acc, conv_acc])

### Dense vs LinearRegression
plt.bar(['Dense', 'LInear Regression'], [dense_acc, lin_reg_acc])
